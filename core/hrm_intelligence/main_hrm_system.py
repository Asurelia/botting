"""
SystÃ¨me HRM Intelligence Principal - Point d'entrÃ©e unifiÃ©e
Orchestrateur central pour tous les composants d'intelligence HRM

Auteur: Claude Code
Version: 1.0.0
"""

import sys
import os
import time
import json
import logging
import threading
import signal
from pathlib import Path
from typing import Dict, Any, Optional, Callable
from dataclasses import dataclass, asdict
from datetime import datetime

# Ajouter le chemin du module HRM
sys.path.append(str(Path(__file__).parent))

# Imports du systÃ¨me HRM
try:
    import hrm_core
    import adaptive_learner
    import intelligent_decision_maker
    import quest_tracker

    from hrm_core import HRMBot, GameState, HRMDecision
    from adaptive_learner import AdaptiveLearner, LearningExperience
    from intelligent_decision_maker import IntelligentDecisionMaker
    from quest_tracker import QuestTracker, Quest
except ImportError as e:
    print(f"Erreur d'import HRM: {e}")
    print("Assurez-vous que tous les modules HRM sont installÃ©s")
    sys.exit(1)

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('G:/Botting/logs/hrm_system.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class HRMSystemConfig:
    """Configuration du systÃ¨me HRM"""
    # Chemins
    models_path: str = "G:/Botting/models"
    data_path: str = "G:/Botting/data/hrm"
    logs_path: str = "G:/Botting/logs"

    # ParamÃ¨tres d'apprentissage
    learning_enabled: bool = True
    auto_save_interval: int = 300  # 5 minutes
    max_experiences: int = 10000

    # ParamÃ¨tres de performance
    decision_timeout: float = 1.0  # 1 seconde max par dÃ©cision
    screenshot_interval: float = 0.5  # Capture d'Ã©cran toutes les 0.5s
    quest_check_interval: float = 5.0  # VÃ©rification quÃªtes toutes les 5s

    # ParamÃ¨tres de comportement
    human_like_delays: bool = True
    random_actions_probability: float = 0.02  # 2% d'actions alÃ©atoires
    adaptive_learning_rate: float = 0.001

    # ParamÃ¨tres de debug
    debug_mode: bool = False
    save_screenshots: bool = False
    verbose_logging: bool = False

class HRMIntelligenceSystem:
    """SystÃ¨me d'intelligence HRM unifiÃ©"""

    def __init__(self, config: Optional[HRMSystemConfig] = None, player_id: str = "tactical_bot"):
        self.config = config or HRMSystemConfig()
        self.player_id = player_id
        self.running = False
        self.paused = False

        # Statistiques du systÃ¨me
        self.stats = {
            "start_time": time.time(),
            "decisions_made": 0,
            "successful_actions": 0,
            "failed_actions": 0,
            "quests_completed": 0,
            "learning_sessions": 0,
            "total_reward": 0.0
        }

        # CrÃ©er les rÃ©pertoires nÃ©cessaires
        self._setup_directories()

        # Initialiser les composants
        self._initialize_components()

        # Handlers pour signaux systÃ¨me
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

        logger.info(f"ðŸ¤– SystÃ¨me HRM Intelligence initialisÃ© pour {player_id}")

    def _setup_directories(self):
        """CrÃ©e les rÃ©pertoires nÃ©cessaires"""
        directories = [
            self.config.models_path,
            self.config.data_path,
            self.config.logs_path,
            f"{self.config.data_path}/screenshots",
            f"{self.config.data_path}/learning",
            f"{self.config.data_path}/quests"
        ]

        for directory in directories:
            os.makedirs(directory, exist_ok=True)

    def _initialize_components(self):
        """Initialise tous les composants HRM"""
        try:
            # ModÃ¨le HRM principal
            model_path = f"{self.config.models_path}/hrm_model_{self.player_id}.pth"
            self.hrm_bot = HRMBot(model_path if Path(model_path).exists() else None)

            # Apprentissage adaptatif
            self.adaptive_learner = AdaptiveLearner(
                player_id=self.player_id,
                max_experiences=self.config.max_experiences
            )

            # DÃ©cideur intelligent
            self.decision_maker = IntelligentDecisionMaker()

            # Tracker de quÃªtes
            quest_db_path = f"{self.config.data_path}/quests/quests_{self.player_id}.db"
            self.quest_tracker = QuestTracker(db_path=quest_db_path)

            # Timers pour actions pÃ©riodiques
            self.last_save_time = time.time()
            self.last_screenshot_time = time.time()
            self.last_quest_check_time = time.time()

            logger.info("âœ… Tous les composants HRM initialisÃ©s avec succÃ¨s")

        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'initialisation: {e}")
            raise

    def _signal_handler(self, signum, frame):
        """Gestionnaire pour les signaux systÃ¨me"""
        logger.info(f"Signal {signum} reÃ§u, arrÃªt en cours...")
        self.stop()

    def get_current_game_state(self) -> Optional[GameState]:
        """
        RÃ©cupÃ¨re l'Ã©tat actuel du jeu
        Ã€ adapter selon l'interface de votre jeu spÃ©cifique
        """
        try:
            # TODO: Remplacer par la vraie logique de capture d'Ã©tat
            # Ceci est un exemple de base

            current_time = time.time()

            # Ã‰tat simulÃ© pour les tests
            mock_state = GameState(
                player_position=(100, 200),  # Ã€ remplacer par vraie position
                player_health=85.0,  # Ã€ remplacer par vraie santÃ©
                player_mana=60.0,    # Ã€ remplacer par vrai mana
                player_level=15,     # Ã€ remplacer par vrai niveau
                nearby_entities=[],  # Ã€ remplacer par vraies entitÃ©s
                available_actions=["move_up", "move_down", "attack", "use_potion"],
                current_quest=None,  # Sera mis Ã  jour par quest_tracker
                inventory_state={},  # Ã€ remplacer par vrai inventaire
                timestamp=current_time,
                game_time=datetime.now().strftime("%H:%M"),
                fps=60.0,           # Ã€ remplacer par vrai FPS
                latency=25.0        # Ã€ remplacer par vraie latence
            )

            # Mettre Ã  jour avec les quÃªtes actives
            active_quests = self.quest_tracker.get_active_quests()
            if active_quests:
                mock_state.current_quest = active_quests[0].title

            return mock_state

        except Exception as e:
            logger.error(f"Erreur lors de la capture d'Ã©tat: {e}")
            return None

    def make_intelligent_decision(self, game_state: GameState) -> Optional[Dict[str, Any]]:
        """Prend une dÃ©cision intelligente basÃ©e sur l'Ã©tat du jeu"""
        try:
            start_time = time.time()

            # 1. DÃ©cision de base via HRM
            base_decision = self.hrm_bot.decide_action(game_state)

            # 2. Enrichissement par le dÃ©cideur intelligent
            enhanced_decision = self.decision_maker.make_enhanced_decision(
                base_action=base_decision.action,
                confidence=base_decision.confidence,
                game_context={
                    "current_quest": game_state.current_quest,
                    "player_health": game_state.player_health,
                    "nearby_entities": len(game_state.nearby_entities),
                    "inventory_items": len(game_state.inventory_state)
                }
            )

            # 3. Adaptation comportementale humaine
            if self.config.human_like_delays:
                behavior_config = self.adaptive_learner.get_human_like_behavior()
                enhanced_decision["human_delay"] = behavior_config.get("reaction_delay", 0.1)

            # 4. Mise Ã  jour des statistiques
            self.stats["decisions_made"] += 1
            decision_time = time.time() - start_time

            decision_data = {
                "base_decision": asdict(base_decision),
                "enhanced_decision": enhanced_decision,
                "decision_time": decision_time,
                "game_state_snapshot": {
                    "timestamp": game_state.timestamp,
                    "player_health": game_state.player_health,
                    "current_quest": game_state.current_quest
                }
            }

            if self.config.debug_mode:
                logger.debug(f"DÃ©cision prise en {decision_time:.3f}s: {enhanced_decision['final_action']}")

            return decision_data

        except Exception as e:
            logger.error(f"Erreur lors de la prise de dÃ©cision: {e}")
            return None

    def learn_from_action_result(self, decision_data: Dict[str, Any], success: bool, reward: float = 0.0):
        """Apprend du rÃ©sultat d'une action"""
        try:
            # Mise Ã  jour des statistiques
            if success:
                self.stats["successful_actions"] += 1
            else:
                self.stats["failed_actions"] += 1

            self.stats["total_reward"] += reward

            # Apprentissage HRM
            base_decision = HRMDecision(**decision_data["base_decision"])
            self.hrm_bot.learn_from_outcome(base_decision, success, reward)

            # Apprentissage adaptatif
            if self.config.learning_enabled:
                experience = LearningExperience(
                    state_data=decision_data["game_state_snapshot"],
                    action_taken=decision_data["enhanced_decision"]["final_action"],
                    reward_received=reward,
                    outcome_success=success,
                    context_info=decision_data["enhanced_decision"].get("context", {})
                )

                self.adaptive_learner.add_experience(experience)
                self.stats["learning_sessions"] += 1

            if self.config.debug_mode:
                logger.debug(f"Apprentissage: Action={'SUCCÃˆS' if success else 'Ã‰CHEC'}, Reward={reward}")

        except Exception as e:
            logger.error(f"Erreur lors de l'apprentissage: {e}")

    def update_quest_progress(self):
        """Met Ã  jour la progression des quÃªtes"""
        try:
            current_time = time.time()

            if current_time - self.last_quest_check_time >= self.config.quest_check_interval:
                # DÃ©tecter les quÃªtes via OCR
                detected_quests = self.quest_tracker.detect_quests_from_screen()

                # Obtenir des recommandations
                game_state = self.get_current_game_state()
                if game_state:
                    recommendations = self.quest_tracker.get_quest_recommendations({
                        "player_level": game_state.player_level,
                        "current_area": "auto_detected"  # Ã€ amÃ©liorer
                    })

                    if self.config.verbose_logging and recommendations:
                        logger.info(f"Recommandations de quÃªtes: {len(recommendations)} trouvÃ©es")

                self.last_quest_check_time = current_time

        except Exception as e:
            logger.error(f"Erreur lors de la mise Ã  jour des quÃªtes: {e}")

    def periodic_save(self):
        """Sauvegarde pÃ©riodique des donnÃ©es"""
        try:
            current_time = time.time()

            if current_time - self.last_save_time >= self.config.auto_save_interval:
                # Sauvegarder le modÃ¨le HRM
                model_path = f"{self.config.models_path}/hrm_model_{self.player_id}.pth"
                self.hrm_bot.save_model(model_path)

                # Sauvegarder les donnÃ©es d'apprentissage
                learning_path = f"{self.config.data_path}/learning/adaptive_learning_{self.player_id}.json"
                self.adaptive_learner.save_learning_data(learning_path)

                # Sauvegarder les statistiques
                stats_path = f"{self.config.data_path}/system_stats_{self.player_id}.json"
                with open(stats_path, 'w', encoding='utf-8') as f:
                    json.dump(self.stats, f, indent=2)

                self.last_save_time = current_time
                logger.info("ðŸ’¾ Sauvegarde automatique effectuÃ©e")

        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde: {e}")

    def run_main_loop(self):
        """Boucle principale du systÃ¨me"""
        logger.info("ðŸš€ DÃ©marrage de la boucle principale HRM Intelligence")
        self.running = True

        try:
            while self.running:
                if self.paused:
                    time.sleep(0.1)
                    continue

                # Obtenir l'Ã©tat du jeu
                game_state = self.get_current_game_state()
                if not game_state:
                    time.sleep(0.1)
                    continue

                # Prendre une dÃ©cision intelligente
                decision_data = self.make_intelligent_decision(game_state)
                if not decision_data:
                    time.sleep(0.1)
                    continue

                # TODO: ExÃ©cuter l'action dans le jeu
                # action_result = execute_game_action(decision_data["enhanced_decision"]["final_action"])

                # Pour les tests, simuler un rÃ©sultat
                import random
                simulated_success = random.random() > 0.3  # 70% de succÃ¨s
                simulated_reward = random.uniform(1.0, 10.0) if simulated_success else 0.0

                # Apprendre du rÃ©sultat
                self.learn_from_action_result(decision_data, simulated_success, simulated_reward)

                # TÃ¢ches pÃ©riodiques
                self.update_quest_progress()
                self.periodic_save()

                # DÃ©lai basÃ© sur la configuration
                if self.config.human_like_delays:
                    delay = decision_data.get("enhanced_decision", {}).get("human_delay", 0.1)
                else:
                    delay = 0.05

                time.sleep(delay)

        except KeyboardInterrupt:
            logger.info("Interruption clavier dÃ©tectÃ©e")
        except Exception as e:
            logger.error(f"Erreur dans la boucle principale: {e}")
        finally:
            self.stop()

    def start(self):
        """DÃ©marre le systÃ¨me en arriÃ¨re-plan"""
        if self.running:
            logger.warning("Le systÃ¨me est dÃ©jÃ  en cours d'exÃ©cution")
            return

        self.main_thread = threading.Thread(target=self.run_main_loop, daemon=True)
        self.main_thread.start()
        logger.info("âœ… SystÃ¨me HRM Intelligence dÃ©marrÃ© en arriÃ¨re-plan")

    def stop(self):
        """ArrÃªte le systÃ¨me proprement"""
        logger.info("ðŸ›‘ ArrÃªt du systÃ¨me HRM Intelligence...")
        self.running = False

        # Sauvegarde finale
        try:
            self.periodic_save()
            logger.info("ðŸ’¾ Sauvegarde finale effectuÃ©e")
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde finale: {e}")

        logger.info("âœ… SystÃ¨me HRM Intelligence arrÃªtÃ©")

    def pause(self):
        """Met en pause le systÃ¨me"""
        self.paused = True
        logger.info("â¸ï¸  SystÃ¨me mis en pause")

    def resume(self):
        """Reprend l'exÃ©cution du systÃ¨me"""
        self.paused = False
        logger.info("â–¶ï¸  SystÃ¨me repris")

    def get_system_status(self) -> Dict[str, Any]:
        """Retourne le statut du systÃ¨me"""
        uptime = time.time() - self.stats["start_time"]

        return {
            "running": self.running,
            "paused": self.paused,
            "uptime_seconds": uptime,
            "uptime_formatted": f"{uptime//3600:.0f}h {(uptime%3600)//60:.0f}m {uptime%60:.0f}s",
            "statistics": self.stats.copy(),
            "performance": self.hrm_bot.get_performance_report(),
            "config": asdict(self.config)
        }

def main():
    """Point d'entrÃ©e principal"""
    import argparse

    parser = argparse.ArgumentParser(description="SystÃ¨me HRM Intelligence pour TacticalBot")
    parser.add_argument("--player-id", default="tactical_bot", help="ID du joueur")
    parser.add_argument("--debug", action="store_true", help="Mode debug")
    parser.add_argument("--test", action="store_true", help="Mode test avec simulation")
    parser.add_argument("--config", help="Fichier de configuration JSON")

    args = parser.parse_args()

    # Configuration
    config = HRMSystemConfig()
    if args.config and Path(args.config).exists():
        with open(args.config, 'r', encoding='utf-8') as f:
            config_data = json.load(f)
            for key, value in config_data.items():
                if hasattr(config, key):
                    setattr(config, key, value)

    if args.debug:
        config.debug_mode = True
        config.verbose_logging = True

    # Initialisation du systÃ¨me
    try:
        system = HRMIntelligenceSystem(config=config, player_id=args.player_id)

        if args.test:
            logger.info("ðŸ§ª Mode test activÃ© - exÃ©cution pour 30 secondes")
            system.start()
            time.sleep(30)
            system.stop()
        else:
            logger.info("ðŸŽ® Mode production - appuyez sur Ctrl+C pour arrÃªter")
            system.run_main_loop()

    except KeyboardInterrupt:
        logger.info("ArrÃªt demandÃ© par l'utilisateur")
    except Exception as e:
        logger.error(f"Erreur fatale: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
Script de Consultation Gemini pour Consensus IA
Facilite l'interaction avec Gemini CLI pour obtenir un deuxi√®me avis technique
"""

import subprocess
import json
import os
import time
from pathlib import Path
from typing import Dict, List, Any
import logging

logger = logging.getLogger(__name__)

class GeminiConsultant:
    """Interface pour consultation Gemini via CLI"""

    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root or os.getcwd())
        self.consultation_dir = self.project_root / "docs" / "gemini_consultations"
        self.consultation_dir.mkdir(parents=True, exist_ok=True)

        # V√©rification de Gemini CLI
        self.gemini_available = self._check_gemini_cli()

    def _check_gemini_cli(self) -> bool:
        """V√©rifie si Gemini CLI est disponible"""
        try:
            result = subprocess.run(
                ["gemini", "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            return result.returncode == 0
        except (subprocess.TimeoutExpired, FileNotFoundError):
            logger.warning("Gemini CLI non trouv√©. Installation requise.")
            return False

    def prepare_consultation(self, topic: str) -> Dict[str, Any]:
        """Pr√©pare une consultation structur√©e"""

        consultation_data = {
            "topic": topic,
            "timestamp": time.strftime("%Y%m%d_%H%M%S"),
            "claude_analysis": self._get_claude_analysis(),
            "technical_context": self._get_technical_context(),
            "specific_questions": self._get_specific_questions(topic),
            "consultation_prompt": self._build_consultation_prompt(topic)
        }

        return consultation_data

    def _get_claude_analysis(self) -> Dict[str, Any]:
        """R√©sume l'analyse de Claude sur le projet"""
        return {
            "current_architecture": {
                "vision_system": "Hybrid YOLO + Template Matching",
                "modules": ["screen_analyzer", "hybrid_detector", "detection_adapter", "dataset_bootstrap"],
                "status": "Implemented and functional"
            },
            "identified_improvements": {
                "temporal_predictive": "Predictive analytics and long-term planning",
                "social_multi_agent": "Multi-character coordination and social intelligence",
                "metacognitive": "Self-improvement and performance introspection",
                "behavioral_advanced": "Complex personality and emotional simulation"
            },
            "technical_challenges": [
                "Real-time state synchronization",
                "Uncertainty management in decision making",
                "Scalable knowledge representation",
                "Human-like behavior simulation"
            ]
        }

    def _get_technical_context(self) -> Dict[str, Any]:
        """Collecte le contexte technique du projet"""
        context = {
            "language": "Python 3.11",
            "frameworks": ["OpenCV", "Ultralytics YOLO", "NumPy", "Threading"],
            "target_platform": "Windows 10/11",
            "performance_requirements": "Real-time (>30 FPS vision, <100ms decisions)",
            "constraints": [
                "Anti-detection requirements",
                "Resource efficiency",
                "Modular architecture",
                "Backward compatibility"
            ]
        }

        # Lecture des fichiers de config s'ils existent
        config_files = [
            "config/bot_config.json",
            "config/yolo_config.json",
            "requirements.txt"
        ]

        for config_file in config_files:
            config_path = self.project_root / config_file
            if config_path.exists():
                try:
                    if config_file.endswith('.json'):
                        with open(config_path, 'r') as f:
                            context[f"config_{config_path.stem}"] = json.load(f)
                    else:
                        with open(config_path, 'r') as f:
                            context[f"content_{config_path.stem}"] = f.read()
                except Exception as e:
                    logger.warning(f"Erreur lecture {config_file}: {e}")

        return context

    def _get_specific_questions(self, topic: str) -> List[str]:
        """G√©n√®re les questions sp√©cifiques selon le sujet"""

        question_templates = {
            "autonomy_architecture": [
                "Quelle architecture recommandes-tu pour un bot autonome √©volutif dans un MMORPG ?",
                "Comment structurer la prise de d√©cision multi-objectifs en temps r√©el ?",
                "Patterns optimaux pour gestion d'√©tat complexe (personnage + monde + historique) ?",
                "Gestion de la concurrence entre modules de perception, d√©cision et action ?"
            ],
            "learning_intelligence": [
                "Reinforcement Learning vs Decision Trees vs Hybrid pour autonomie MMORPG ?",
                "Comment mod√©liser l'incertitude et prise de risque dans un monde persistant ?",
                "M√©canismes d'apprentissage incr√©mental depuis guides et exp√©rience ?",
                "Gestion exploration vs exploitation avec contraintes anti-d√©tection ?"
            ],
            "knowledge_management": [
                "Repr√©sentation optimale base de connaissances √©volutive (Graph/Vector/Traditional DB) ?",
                "M√©canismes mise √† jour automatique depuis sources externes ?",
                "Gestion v√©racit√© et obsolescence des donn√©es de jeu ?",
                "Fusion intelligente connaissances statiques vs dynamiques ?"
            ],
            "behavioral_simulation": [
                "Simulation comportement humain r√©aliste dans MMORPG ?",
                "Mod√©lisation personnalit√© √©volutive et √©motions ?",
                "Patterns temporels naturels (pauses, variations, fatigue) ?",
                "M√©triques pour mesurer 'humanit√©' du comportement ?"
            ]
        }

        return question_templates.get(topic, [
            f"Analyse technique approfondie du sujet : {topic}",
            f"Recommendations d'impl√©mentation pour : {topic}",
            f"D√©fis et solutions pour : {topic}"
        ])

    def _build_consultation_prompt(self, topic: str) -> str:
        """Construit le prompt de consultation pour Gemini"""

        prompt_template = f"""
# Consultation Technique - {topic.title()}

## Contexte Projet
Bot DOFUS autonome avec vision hybride YOLO + Template Matching.
Objectif: Autonomie quasi-humaine avec apprentissage et adaptation.

## Architecture Actuelle (par Claude)
- ‚úÖ Vision hybride impl√©ment√©e (YOLO + Template)
- ‚úÖ Adaptation dynamique selon contexte de jeu
- ‚úÖ Fusion intelligente des d√©tections avec cross-validation
- ‚úÖ Bootstrap dataset depuis template matching existant

## Axes d'Am√©lioration Identifi√©s
1. **Temporel & Pr√©dictif**: Analytics pr√©dictives, planification long-terme
2. **Social & Multi-Agent**: Coordination multi-personnages, intelligence sociale
3. **M√©tacognitif**: Auto-am√©lioration, introspection performance
4. **Comportemental**: Personnalit√© complexe, simulation √©motionnelle

## Questions Sp√©cifiques
{chr(10).join([f"- {q}" for q in self._get_specific_questions(topic)])}

## Format R√©ponse Demand√©
1. **ANALYSE ARCHITECTURE**
   - √âvaluation approche actuelle
   - Am√©liorations recommand√©es
   - Patterns sugg√©r√©s

2. **PRIORISATION TECHNIQUE**
   - Top 3 am√©liorations par impact
   - Justification et timeline
   - Risques techniques

3. **RECOMMENDATIONS CONCR√àTES**
   - Technologies/frameworks sp√©cifiques
   - Patterns d'impl√©mentation
   - M√©triques de succ√®s

4. **CONSENSUS/DIVERGENCES**
   - Points d'accord avec analyse Claude
   - Alternatives propos√©es
   - Synth√®se recommandations

---
Merci pour ton analyse technique approfondie !
"""

        return prompt_template

    def run_consultation(self, topic: str, interactive: bool = True) -> Dict[str, Any]:
        """Lance une consultation avec Gemini"""

        if not self.gemini_available:
            logger.error("Gemini CLI non disponible")
            return {"error": "Gemini CLI non trouv√©"}

        consultation = self.prepare_consultation(topic)

        # Sauvegarde de la consultation
        consultation_file = self.consultation_dir / f"consultation_{topic}_{consultation['timestamp']}.json"

        try:
            with open(consultation_file, 'w', encoding='utf-8') as f:
                json.dump(consultation, f, indent=2, ensure_ascii=False)

            print(f"üìã Consultation pr√©par√©e: {consultation_file}")
            print("\n" + "="*60)
            print("PROMPT POUR GEMINI CLI:")
            print("="*60)
            print(consultation["consultation_prompt"])
            print("="*60)

            if interactive:
                input("\n‚ñ∂Ô∏è  Copiez le prompt ci-dessus dans Gemini CLI, puis appuyez sur Entr√©e...")

                # Demande de coller la r√©ponse
                print("\nüìù Collez la r√©ponse de Gemini ci-dessous (terminez par une ligne vide):")

                gemini_response = []
                while True:
                    line = input()
                    if line.strip() == "" and gemini_response:
                        break
                    gemini_response.append(line)

                response_text = "\n".join(gemini_response)

                # Sauvegarde de la r√©ponse
                consultation["gemini_response"] = response_text
                consultation["analysis_complete"] = True

                with open(consultation_file, 'w', encoding='utf-8') as f:
                    json.dump(consultation, f, indent=2, ensure_ascii=False)

                # G√©n√©ration du consensus
                consensus = self._generate_consensus(consultation)
                consultation["consensus"] = consensus

                with open(consultation_file, 'w', encoding='utf-8') as f:
                    json.dump(consultation, f, indent=2, ensure_ascii=False)

                print(f"\n‚úÖ Consultation compl√®te sauvegard√©e: {consultation_file}")
                return consultation

            else:
                print(f"\nüí° Mode non-interactif: Utilisez le prompt manuellement avec Gemini CLI")
                return consultation

        except Exception as e:
            logger.error(f"Erreur consultation: {e}")
            return {"error": str(e)}

    def _generate_consensus(self, consultation: Dict[str, Any]) -> Dict[str, Any]:
        """G√©n√®re une synth√®se consensus entre Claude et Gemini"""

        gemini_response = consultation.get("gemini_response", "")

        # Analyse basique de la r√©ponse (pourrait √™tre am√©lior√©e avec NLP)
        consensus = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "topic": consultation["topic"],
            "claude_position": consultation["claude_analysis"],
            "gemini_response_length": len(gemini_response),
            "key_agreements": [],
            "key_differences": [],
            "synthesis": {},
            "next_actions": []
        }

        # Recherche de mots-cl√©s dans la r√©ponse de Gemini
        agreement_keywords = ["d'accord", "confirme", "excellent", "recommande aussi"]
        difference_keywords = ["cependant", "plut√¥t", "alternative", "diff√©rente approche"]

        for keyword in agreement_keywords:
            if keyword.lower() in gemini_response.lower():
                consensus["key_agreements"].append(f"Mention de '{keyword}' dans la r√©ponse")

        for keyword in difference_keywords:
            if keyword.lower() in gemini_response.lower():
                consensus["key_differences"].append(f"Mention de '{keyword}' dans la r√©ponse")

        # Recommandations g√©n√©riques
        consensus["next_actions"] = [
            "Analyser en d√©tail les points de convergence et divergence",
            "Prioriser les am√©liorations selon consensus",
            "Impl√©menter les solutions consensuelles en premier",
            "It√©rer sur les points de divergence"
        ]

        return consensus

    def list_consultations(self) -> List[Dict[str, Any]]:
        """Liste les consultations pr√©c√©dentes"""
        consultations = []

        for consultation_file in self.consultation_dir.glob("consultation_*.json"):
            try:
                with open(consultation_file, 'r', encoding='utf-8') as f:
                    consultation = json.load(f)
                    consultations.append({
                        "file": consultation_file.name,
                        "topic": consultation.get("topic", "Unknown"),
                        "timestamp": consultation.get("timestamp", "Unknown"),
                        "complete": consultation.get("analysis_complete", False)
                    })
            except Exception as e:
                logger.warning(f"Erreur lecture {consultation_file}: {e}")

        return sorted(consultations, key=lambda x: x["timestamp"], reverse=True)

# Interface CLI
def main():
    import argparse

    parser = argparse.ArgumentParser(description="Consultation Gemini pour consensus IA")
    parser.add_argument("topic", choices=[
        "autonomy_architecture",
        "learning_intelligence",
        "knowledge_management",
        "behavioral_simulation"
    ], help="Sujet de consultation")
    parser.add_argument("--non-interactive", action="store_true", help="Mode non-interactif")
    parser.add_argument("--list", action="store_true", help="Lister les consultations")

    args = parser.parse_args()

    consultant = GeminiConsultant()

    if args.list:
        consultations = consultant.list_consultations()
        print(f"\nüìö {len(consultations)} consultation(s) trouv√©e(s):")
        for consultation in consultations:
            status = "‚úÖ Compl√®te" if consultation["complete"] else "‚è≥ En cours"
            print(f"  - {consultation['topic']} ({consultation['timestamp']}) {status}")
        return

    print(f"\nü§ù Lancement consultation Gemini: {args.topic}")

    result = consultant.run_consultation(
        topic=args.topic,
        interactive=not args.non_interactive
    )

    if "error" in result:
        print(f"‚ùå Erreur: {result['error']}")
    else:
        print(f"\n‚úÖ Consultation termin√©e !")
        if result.get("analysis_complete"):
            print(f"üìä Consensus g√©n√©r√© et sauvegard√©")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    main()